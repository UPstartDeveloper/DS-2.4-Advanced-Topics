{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stack_Overflow_text_classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPCJ94/xAf6NHIMXcPqTID1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UPstartDeveloper/DS-2.4-Advanced-Topics/blob/main/Notebooks/NLP/Stack_Overflow_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpU5yadWuNIK"
      },
      "source": [
        "# What Language is It? \n",
        "## Text Classification of Stack Overflow Questions, using Keras \n",
        "\n",
        "Originally adapted from the botton of [this tutorial](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb) on binary text classification from Tensorflow. The original notebook stated:\n",
        "\n",
        "> ### Exercise: multiclass classification on Stack Overflow questions\n",
        "\n",
        "> This tutorial showed how to train a binary classifier from scratch on the IMDB dataset. As an exercise, you can modify this notebook to train a multiclass classifier to predict the tag of a programming question on [Stack Overflow](http://stackoverflow.com/).\n",
        "\n",
        "> We have prepared a [dataset](http://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz) for you to use containing the body of several thousand programming questions (for example, \"How can sort a dictionary by value in Python?\") posted to Stack Overflow. Each of these is labeled with exactly one tag (either Python, CSharp, JavaScript, or Java). Your task is to take a question as input, and predict the appropriate tag, in this case, Python. \n",
        "\n",
        "> The dataset you will work with contains several thousand questions extracted from the much larger public Stack Overflow dataset on [BigQuery](https://console.cloud.google.com/marketplace/details/stack-exchange/stack-overflow), which contains more than 17 million posts.\n",
        "\n",
        "> After downloading the dataset, you will find it has a similar directory structure to the IMDB dataset you worked with previously:\n",
        "\n",
        "> ```\n",
        "train/\n",
        "...python/\n",
        "......0.txt\n",
        "......1.txt\n",
        "...javascript/\n",
        "......0.txt\n",
        "......1.txt\n",
        "...csharp/\n",
        "......0.txt\n",
        "......1.txt\n",
        "...java/\n",
        "......0.txt\n",
        "......1.txt\n",
        "```\n",
        "\n",
        "> Note: to increase the difficulty of the classification problem, we have replaced any occurences of the words Python, CSharp, JavaScript, or Java in the programming questions with the word *blank* (as many questions contain the language they're about). \n",
        "\n",
        "> To complete this exercise, you should modify this notebook to work with the Stack Overflow dataset by making the following modifications:\n",
        "\n",
        "> 1. At the top of your notebook, update the code that downloads the IMDB dataset with code to download the [Stack Overflow dataset](http://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz) we have prepreared. As the Stack Overflow dataset has a similar directory structure, you will not need to make many modifications. \n",
        "\n",
        "> 2. Modify the last layer of your model to read `Dense(4)`, as there are now four output classes.\n",
        "\n",
        "> 3. When you compile your model, change the loss to `losses.SparseCategoricalCrossentropy`. This is the correct loss function to use for a multiclass classification problem, when the labels for each class are integers (in our case, they can be 0, *1*, *2*, or *3*).\n",
        "\n",
        "> 4. Once these changes are complete, you will be able to train a multiclass classifier. \n",
        "\n",
        "> If you get stuck, you can find a solution [here](https://github.com/tensorflow/examples/blob/master/community/en/text_classification_solution.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uq9_MN0vcgW"
      },
      "source": [
        "## Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhOmDy11veyz"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVqEhxORvked"
      },
      "source": [
        "## What Version of Tensorflow is This?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUeGYEZcvi2x",
        "outputId": "9fd8e3d4-2106-4536-f3cb-d638c737da89"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUQufujHvyMU"
      },
      "source": [
        "## Download and Explore the Stack Overflow Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "538ZU0DTv1MZ"
      },
      "source": [
        "url = \"http://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz\"\n",
        "\n",
        "# adds a dir for the dataset\n",
        "dataset = tf.keras.utils.get_file(\"stack_overflow_16k.tar.gz\", url,\n",
        "                                    untar=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "# getting the full path to the directory\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiftx5OWwWWD",
        "outputId": "07ad4fe1-7366-4fb3-ee5c-914ba0df61b3"
      },
      "source": [
        "# listing all the sub paths in the dataset's ZIP folder\n",
        "os.listdir(dataset_dir)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'stack_overflow_16k.tar.gz.tar.gz',\n",
              " 'test',\n",
              " 'train',\n",
              " 'README.md',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGzqEtOIwgkU",
        "outputId": "1b95a5b1-be5f-4193-e46e-08b4273f74d4"
      },
      "source": [
        "# do the same just for the training data directory\n",
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "os.listdir(train_dir)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['java', 'csharp', 'javascript', 'python']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvK6Mkthw_Sv"
      },
      "source": [
        "**Example Data**:\n",
        "Let's take a look at one of the questions for Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-uVbtqvxKaz",
        "outputId": "09a1c406-08b7-4484-fab5-5cbaf617eb37"
      },
      "source": [
        "sample_file = os.path.join(train_dir, 'python/102.txt')\n",
        "with open(sample_file) as f:\n",
        "  print(f.read())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"why not use self.varibale_name while calling instance attribute when we create a class which is having instance attribute,why don't we call the instance attribute using self keyword.please..class car:.    def __init__(self, type, color):.        self.type = type.        self.color = color...c1 = car('suv','red').print(c1.type)...why not print(c1.self.type), because self.type is the actual attribute..got the following error:..attributeerror: 'car' object has no attribute 'self'\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4vXEAsDxj0S"
      },
      "source": [
        "## Load the dataset\n",
        "\n",
        "In this step we'll do a number of things to prepare the data for text classification including:\n",
        "\n",
        "1.   Loading the data using `tf.data.Dataset` ([docs](https://www.tensorflow.org/guide/data))\n",
        "2.   Splitting the data into training, validation, and testing sets\n",
        "\n",
        "For now, let's find our training data:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py2NhjeK0rz8",
        "outputId": "7e9ef28c-1643-4725-be70-70d18a1fd153"
      },
      "source": [
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "# creating trainin\n",
        "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'train', \n",
        "    batch_size=batch_size, \n",
        "    validation_split=0.2, \n",
        "    subset='training',  # let's take the other 80% of the training data\n",
        "    seed=seed)  # use the same seed or don't shuffle, to guarantees no overlap "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 files belonging to 4 classes.\n",
            "Using 6400 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH0gWrzX02Oz",
        "outputId": "c33db62f-065e-40f7-846b-e4528f4cb1c9"
      },
      "source": [
        "# generate 1 batch (as an example)\n",
        "for text_batch, label_batch in raw_train_ds.take(1):\n",
        "  # show the review and the review of 3 samples from the batches\n",
        "  for i in range(3):\n",
        "    print(\"Review\", text_batch.numpy()[i])\n",
        "    print(\"Label\", label_batch.numpy()[i])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review b'\"my tester is going to the wrong constructor i am new to programming so if i ask a question that can be easily fixed, please forgive me. my program has a tester class with a main. when i send that to my regularpolygon class, it sends it to the wrong constructor. i have two constructors. 1 without perameters..public regularpolygon().    {.       mynumsides = 5;.       mysidelength = 30;.    }//end default constructor...and my second, with perameters. ..public regularpolygon(int numsides, double sidelength).    {.        mynumsides = numsides;.        mysidelength = sidelength;.    }// end constructor...in my tester class i have these two lines:..regularpolygon shape = new regularpolygon(numsides, sidelength);.        shape.menu();...numsides and sidelength were declared and initialized earlier in the testing class...so what i want to happen, is the tester class sends numsides and sidelength to the second constructor and use it in that class. but it only uses the default constructor, which therefor ruins the whole rest of the program. can somebody help me?..for those of you who want to see more of my code: here you go..public double vertexangle().    {.        system.out.println(\"\"the vertex angle method: \"\" + mynumsides);// prints out 5.        system.out.println(\"\"the vertex angle method: \"\" + mysidelength); // prints out 30..        double vertexangle;.        vertexangle = ((mynumsides - 2.0) / mynumsides) * 180.0;.        return vertexangle;.    }//end method vertexangle..public void menu().{.    system.out.println(mynumsides); // prints out what the user puts in.    system.out.println(mysidelength); // prints out what the user puts in.    gotographic();.    calcr(mynumsides, mysidelength);.    calcr(mynumsides, mysidelength);.    print(); .}// end menu...this is my entire tester class:..public static void main(string[] arg).{.    int numsides;.    double sidelength;.    scanner keyboard = new scanner(system.in);..    system.out.println(\"\"welcome to the regular polygon program!\"\");.    system.out.println();..    system.out.print(\"\"enter the number of sides of the polygon ==&gt; \"\");.    numsides = keyboard.nextint();.    system.out.println();..    system.out.print(\"\"enter the side length of each side ==&gt; \"\");.    sidelength = keyboard.nextdouble();.    system.out.println();..    regularpolygon shape = new regularpolygon(numsides, sidelength);.    shape.menu();.}//end main...for testing it i sent it numsides 4 and sidelength 100.\"\\n'\n",
            "Label 1\n",
            "Review b'\"blank code slow skin detection this code changes the color space to lab and using a threshold finds the skin area of an image. but it\\'s ridiculously slow. i don\\'t know how to make it faster ?    ..from colormath.color_objects import *..def skindetection(img, treshold=80, color=[255,20,147]):..    print img.shape.    res=img.copy().    for x in range(img.shape[0]):.        for y in range(img.shape[1]):.            rgbimg=rgbcolor(img[x,y,0],img[x,y,1],img[x,y,2]).            labimg=rgbimg.convert_to(\\'lab\\', debug=false).            if (labimg.lab_l &gt; treshold):.                res[x,y,:]=color.            else: .                res[x,y,:]=img[x,y,:]..    return res\"\\n'\n",
            "Label 3\n",
            "Review b'\"option and validation in blank i want to add a new option on my system where i want to add two text files, both rental.txt and customer.txt. inside each text are id numbers of the customer, the videotape they need and the price...i want to place it as an option on my code. right now i have:...add customer.rent return.view list.search.exit...i want to add this as my sixth option. say for example i ordered a video, it would display the price and would let me confirm the price and if i am going to buy it or not...here is my current code:..  import blank.io.*;.    import blank.util.arraylist;.    import static blank.lang.system.out;..    public class rentalsystem{.    static bufferedreader input = new bufferedreader(new inputstreamreader(system.in));.    static file file = new file(\"\"file.txt\"\");.    static arraylist&lt;string&gt; list = new arraylist&lt;string&gt;();.    static int rows;..    public static void main(string[] args) throws exception{.        introduction();.        system.out.print(\"\"nn\"\");.        login();.        system.out.print(\"\"nnnnnnnnnnnnnnnnnnnnnn\"\");.        introduction();.        string repeat;.        do{.            loadfile();.            system.out.print(\"\"nwhat do you want to do?nn\"\");.            system.out.print(\"\"n                    - - - - - - - - - - - - - - - - - - - - - - -\"\");.            system.out.print(\"\"nn                    |     1. add customer    |   2. rent return |n\"\");.            system.out.print(\"\"n                    - - - - - - - - - - - - - - - - - - - - - - -\"\");.            system.out.print(\"\"nn                    |     3. view list       |   4. search      |n\"\");.            system.out.print(\"\"n                    - - - - - - - - - - - - - - - - - - - - - - -\"\");.            system.out.print(\"\"nn                                             |   5. exit        |n\"\");.            system.out.print(\"\"n                                              - - - - - - - - - -\"\");.            system.out.print(\"\"nnchoice:\"\");.            int choice = integer.parseint(input.readline());.            switch(choice){.                case 1:.                    writedata();.                    break;.                case 2:.                    rentdata();.                    break;.                case 3:.                    viewlist();.                    break;.                case 4:.                    search();.                    break;.                case 5:.                    system.out.println(\"\"goodbye!\"\");.                    system.exit(0);.                default:.                    system.out.print(\"\"invalid choice: \"\");.                    break;.            }.            system.out.print(\"\"ndo another task? [y/n] \"\");.            repeat = input.readline();.        }while(repeat.equals(\"\"y\"\"));..        if(repeat!=\"\"y\"\") system.out.println(\"\"ngoodbye!\"\");..    }..    public static void writedata() throws exception{.        system.out.print(\"\"nname: \"\");.        string cname = input.readline();.        system.out.print(\"\"address: \"\");.        string add = input.readline();.        system.out.print(\"\"phone no.: \"\");.        string pno = input.readline();.        system.out.print(\"\"rental amount: \"\");.        string ramount = input.readline();.        system.out.print(\"\"tapenumber: \"\");.        string tno = input.readline();.        system.out.print(\"\"title: \"\");.        string title = input.readline();.        system.out.print(\"\"date borrowed: \"\");.        string dborrowed = input.readline();.        system.out.print(\"\"due date: \"\");.        string ddate = input.readline();.        createline(cname, add, pno, ramount,tno, title, dborrowed, ddate);.        rentdata();.    }..    public static void createline(string name, string address, string phone , string rental, string tapenumber, string title, string borrowed, string due) throws exception{.        filewriter fw = new filewriter(file, true);.        fw.write(\"\"nname: \"\"+name + \"\"naddress: \"\" + address +\"\"nphone no.: \"\"+ phone+\"\"nrentalamount: \"\"+rental+\"\"ntape no.: \"\"+ tapenumber+\"\"ntitle: \"\"+ title+\"\"ndate borrowed: \"\"+borrowed +\"\"ndue date: \"\"+ due+\"\":rn\"\");.        fw.close();.    }..    public static void loadfile() throws exception{.        try{.            list.clear();.            fileinputstream fstream = new fileinputstream(file);.            bufferedreader br = new bufferedreader(new inputstreamreader(fstream));.            rows = 0;.            while( br.ready()).            {.                list.add(br.readline());.                rows++;.            }.            br.close();.        } catch(exception e){.            system.out.println(\"\"list not yet loaded.\"\");.        }.    }..    public static void viewlist(){.        system.out.print(\"\"n~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\"\");.        system.out.print(\"\" |list of all costumers|\"\");.        system.out.print(\"\"~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\"\");.        for(int i = 0; i &lt;rows; i++){.            system.out.println(list.get(i));.        }.    }.        public static void rentdata()throws exception.    {   system.out.print(\"\"n~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\"\");.        system.out.print(\"\" |rent data list|\"\");.        system.out.print(\"\"~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\"\");.        system.out.print(\"\"nenter customer name: \"\");.        string cname = input.readline();.        system.out.print(\"\"date borrowed: \"\");.        string dborrowed = input.readline();.        system.out.print(\"\"due date: \"\");.        string ddate = input.readline();.        system.out.print(\"\"return date: \"\");.        string rdate = input.readline();.        system.out.print(\"\"rent amount: \"\");.        string ramount = input.readline();..        system.out.print(\"\"you pay:\"\"+ramount);...    }.    public static void search()throws exception.    {   system.out.print(\"\"n~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\"\");.        system.out.print(\"\" |search costumers|\"\");.        system.out.print(\"\"~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\"\");.        system.out.print(\"\"nenter costumer name: \"\");.        string cname = input.readline();.        boolean found = false;..        for(int i=0; i &lt; rows; i++){.            string temp[] = list.get(i).split(\"\",\"\");..            if(cname.equals(temp[0])){.            system.out.println(\"\"search result:nyou are \"\" + temp[0] + \"\" from \"\" + temp[1] + \"\".\"\"+ temp[2] + \"\".\"\"+ temp[3] + \"\".\"\"+ temp[4] + \"\".\"\"+ temp[5] + \"\" is \"\" + temp[6] + \"\".\"\"+ temp[7] + \"\" is \"\" + temp[8] + \"\".\"\");.                found = true;.            }.        }..        if(!found){.            system.out.print(\"\"no results.\"\");.        }..    }..        public static boolean evaluate(string uname, string pass){.        if (uname.equals(\"\"admin\"\")&amp;&amp;pass.equals(\"\"12345\"\")) return true;.        else return false;.    }..    public static string login()throws exception{.        bufferedreader input=new bufferedreader(new inputstreamreader(system.in));.        int counter=0;.        do{.            system.out.print(\"\"username:\"\");.            string uname =input.readline();.            system.out.print(\"\"password:\"\");.            string pass =input.readline();..            boolean accept= evaluate(uname,pass);..            if(accept){.                break;.                }else{.                    system.out.println(\"\"incorrect username or password!\"\");.                    counter ++;.                    }.        }while(counter&lt;3);..            if(counter !=3) return \"\"login successful\"\";.            else return \"\"login failed\"\";.            }.        public static void introduction() throws exception{..        system.out.println(\"\"                  - - - - - - - - - - - - - - - - - - - - - - - - -\"\");.        system.out.println(\"\"                  !                  r e n t a l                  !\"\");.        system.out.println(\"\"                   ! ~ ~ ~ ~ ~ !  =================  ! ~ ~ ~ ~ ~ !\"\");.        system.out.println(\"\"                  !                  s y s t e m                  !\"\");.        system.out.println(\"\"                  - - - - - - - - - - - - - - - - - - - - - - - - -\"\");.        }..}\"\\n'\n",
            "Label 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSICl96V1AqT"
      },
      "source": [
        "### What Do the Labels Mean?\n",
        "Let's use Tensorflow to find out what classes they correspond to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfeOC-CA1N01",
        "outputId": "3e198cb6-a0c0-4655-a03c-04cfadf288e2"
      },
      "source": [
        "# note that raw_train_ds is a kind of Tensorflow-defined object called a BatchGenerator\n",
        "# and it works similar to like a normal generator that comes built-in to Python\n",
        "for label in range(4):\n",
        "  print(f\"Label {label} corresponds to {raw_train_ds.class_names[label]}\")  "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label 0 corresponds to csharp\n",
            "Label 1 corresponds to java\n",
            "Label 2 corresponds to javascript\n",
            "Label 3 corresponds to python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Idf1Qi2F1msE"
      },
      "source": [
        "### Find the Validation and Testing sets to use from the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNpybrBG1uyM",
        "outputId": "b8a24121-6cc9-4378-d8e0-c25192576ca0"
      },
      "source": [
        "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'train', \n",
        "    batch_size=batch_size, \n",
        "    validation_split=0.2, \n",
        "    subset='validation', \n",
        "    seed=seed)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 files belonging to 4 classes.\n",
            "Using 1600 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOxtc7Wk10QU",
        "outputId": "35359144-1e01-4aa2-ae39-67a520266050"
      },
      "source": [
        "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'test', \n",
        "    batch_size=batch_size)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 files belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H_-lu-Myb35"
      },
      "source": [
        "## Preprocess the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDc-9474yeh0"
      },
      "source": [
        "def custom_standardization(input_data):\n",
        "  \"\"\"This function came from the original Tensorflow notebook: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb\n",
        "     It allows us to strip HTML text (if present) from our input data.\n",
        "  \"\"\"\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation),\n",
        "                                  '')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc4ZorVH2Qjy"
      },
      "source": [
        "# creating a TextVectorization layer\n",
        "max_features = 10000\n",
        "sequence_length = 250\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=max_features,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ETZQxgL21O_"
      },
      "source": [
        "Next we will call adapt to fit the state of the preprocessing layer to the dataset. This will cause the model to build an index of strings to integers.\n",
        "\n",
        "And remember, only use the training data for this step!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTMG9vhI2624"
      },
      "source": [
        "# Make a text-only dataset (without labels), then call adapt\n",
        "train_text = raw_train_ds.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(train_text)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfE36K4u289o"
      },
      "source": [
        "def vectorize_text(text, label):\n",
        "  \"\"\"\n",
        "  See the result of using this layer to preprocess some data.\n",
        "  This function came from the original Tensorflow notebook: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb\n",
        "  \"\"\"\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer(text), label"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFBbKXKR3Ghy",
        "outputId": "cdccbeaf-cdb0-4741-ee51-f31bb70547b3"
      },
      "source": [
        "# retrieve a batch (of 32 questions and labels) from the dataset\n",
        "text_batch, label_batch = next(iter(raw_train_ds))\n",
        "first_question, first_label = text_batch[0], label_batch[0]\n",
        "print(\"Question\", first_question)\n",
        "# this dict maps the binary label to the actual class name\n",
        "print(\"Label\", raw_train_ds.class_names[first_label])\n",
        "print(\"Vectorized review\", vectorize_text(first_question, first_label))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question tf.Tensor(b'\"unit testing of setters and getters teacher wanted us to do a comprehensive unit test. for me, this will be the first time that i use junit. i am confused about testing set and get methods. do you think should i test them? if the answer is yes; is this code enough for testing?..  public void testsetandget(){.    int a = 10;.    class firstclass = new class();.    firstclass.setvalue(10);.    int value = firstclass.getvalue();.    assert.asserttrue(\"\"error\"\", value==a);.  }...in my code, i think if there is an error, we can\\'t know that the error is deriving because of setter or getter.\"\\n', shape=(), dtype=string)\n",
            "Label java\n",
            "Vectorized review (<tf.Tensor: shape=(1, 250), dtype=int64, numpy=\n",
            "array([[1011,  773,    9, 2456,    8, 1863, 2362,  690, 1267,    4,   40,\n",
            "           5,    1, 1011,  196,   12,   74,   13,   72,   33,    2,   98,\n",
            "         105,   14,    3,   70, 9611,    3,   34,  888,  202,  773,  107,\n",
            "           8,   41,  242,   40,   58,  291,   90,    3,  196,  191,   10,\n",
            "           2,  182,    6,  668,    6,   13,   30, 1187,   12,  773,   22,\n",
            "          42,    1,   28,    5,  140,   29, 5213,   15,   29,    1,   28,\n",
            "          51,    1,    1,    1,    7,   23,   30,    3,  291,   10,   67,\n",
            "           6,   32,   65,  185,  166,  102,   14,    2,   65,    6,    1,\n",
            "         193,    9, 2784,   45, 2410,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0]])>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yoq0_six3iuQ"
      },
      "source": [
        "As a final preprocessing step, we apply the TextVectorization layer created earlier to the train, validation, and test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPG75Jh-3jET"
      },
      "source": [
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "val_ds = raw_val_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfpPayOF3qPP"
      },
      "source": [
        "### Configure the dataset for performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-iXOz_l3o8T"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCvalUyt3xnF"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJmEjBoG3u0r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}