{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Efficient_IMDb_Classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMLp60m30K1Au+479Xwqn5K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UPstartDeveloper/DS-2.4-Advanced-Topics/blob/main/Notebooks/NLP/Efficient_IMDb_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kckuh-aSbJ1C"
      },
      "source": [
        "# Exploring the Data API\n",
        "\n",
        "In this exercise we'll revist the IMDb dataset, but this time we'll use the features of the Tensorflow Data API, `tf.data`, to implement highly performant input pipelines.\n",
        "\n",
        "We'll also take another look at making language models for binary classification, and use an `Embedding` layer to see if we can get a computer to learn the implicit relationships between words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cdbEI04bjME"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaCSJxoLblj8"
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# To Download the Dataset (see Part 1)\n",
        "from pathlib import Path"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_myKm9V-b9Ol"
      },
      "source": [
        "## Part 1: Get the Data\n",
        "\n",
        "**About the IMDb Dataset**:\n",
        "1. 50,000 movies reviews from the Internet Movie Database (IMDb). \n",
        "2. Training and testing data are in `train/` and `test/`\n",
        "3. Both of these directories has their own subdirectories for samples of `pos/` and `neg/` reviews.\n",
        "4. Dataset is *balanced* (\n",
        "  - 12,500 samples per class, in both the training and test data\n",
        "5. The samples themselves are *text files.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4QHemPua238",
        "outputId": "4b46f464-54af-4d21-fcf8-14ab8e5a2b08"
      },
      "source": [
        "# locating the dataset TAR file\n",
        "DOWNLOAD_ROOT = \"http://ai.stanford.edu/~amaas/data/sentiment/\"\n",
        "FILENAME = \"aclImdb_v1.tar.gz\"\n",
        "# downloading it onto the client machine\n",
        "filepath = keras.utils.get_file(FILENAME, DOWNLOAD_ROOT + FILENAME, \n",
        "                                extract=True)\n",
        "# finding a place for it on our machine\n",
        "path = Path(filepath).parent / \"aclImdb\"\n",
        "# here it is!\n",
        "print(path)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.keras/datasets/aclImdb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8x1He7jeov9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}